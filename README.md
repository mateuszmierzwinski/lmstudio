# lmstudio

A lightweight, dependency-free Go client for communicating with LMStudio/OpenAI-compatible Chat APIs.  
It provides message history tracking, context-aware conversations, and logical compression of context to help reduce token usage efficiently.

---

## âœ¨ Features

- ğŸ“¡ Send chat requests to LMStudio-compatible APIs
- ğŸ’¬ Support for context-based conversations using in-memory history
- ğŸ§  Built-in message summarization via logical compression
- ğŸ§ª Mockable interface for testing (`ChatClient`)
- ğŸ’¾ Optional message history persistence
- âš™ï¸ Uses **only the Go standard library** â€” no external dependencies

---

## ğŸ“¦ Installation

```bash
go get github.com/mateuszmierzwinski/lmstudio
```

---

## ğŸ”§ Quick Start

### Create a New Binding

```go
package main

import (
	"fmt"
	"github.com/mateuszmierzwinski/lmstudio"
	"github.com/mateuszmierzwinski/lmstudio/internal/model"
)

func main() {
	client := lmstudio.NewLMStudioQuickBind(
		"http://localhost:1234", // LMStudio or compatible API base URL
		"gpt-3.5-turbo",         // Model name
		"",                      // Optional session ID
	)

	msg := []model.LMAPIMessage{
		{Role: "user", Content: "Tell me a story about a dragon."},
	}

	resp, err := client.Chat(msg, 0.7)
	if err != nil {
		panic(err)
	}

	for _, r := range resp {
		fmt.Println("Assistant:", r.Content)
	}
}
```

---

## ğŸ§  Using Context History

```go
contextID := "session-1"

response, err := client.ChatWithContext([]model.LMAPIMessage{
	{Role: "user", Content: "Who was Alan Turing?"},
}, contextID, 0.6)

if err != nil {
	log.Fatal(err)
}

fmt.Println(response[0].Content)
```

---

## ğŸ” Compressing History (Summarization)

When conversation grows long, compress it using the built-in logic:

```go
history := client.MessageHistory["session-1"]

summary, err := client.LogicalCompressContext(history)
if err != nil {
	log.Fatal(err)
}

fmt.Println("Compressed Summary:", summary.Content)
```

---

## âœ… Interface for Testing

Use the `ChatClient` interface to easily mock the binding:

```go
type ChatClient interface {
	ChatWithContext([]model.LMAPIMessage, string, float64) ([]model.LMAPIMessage, error)
	Chat([]model.LMAPIMessage, float64) ([]model.LMAPIMessage, error)
	LogicalCompressContext([]model.LMAPIMessage) (model.LMAPIMessage, error)
	FlushMessageHistory(string)
	ResetMessageHistory()
}
```

---

## ğŸ§ª Philosophy

This module is intentionally **minimal and dependency-free**.  
It relies only on Goâ€™s standard library (`net/http`, `encoding/json`, `os`, etc.), making it ideal for secure, auditable, and lightweight environments.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ internal/
â”‚   â””â”€â”€ model/            # API request/response types
â”œâ”€â”€ lmstudio/             # Core logic (binding, interface)
â”œâ”€â”€ go.mod
â””â”€â”€ README.md
```

---

## ğŸ›  Advanced Configuration

Create a fully customized binding:

```go
binding := lmstudio.NewLMStudioBinding(
	"http://localhost:1234", // Base URL
	"your-auth-token",       // Auth token (optional)
	"gpt-3.5-turbo",         // Model name
	"./history.json",        // Optional history persistence file
	10*time.Second,          // Timeout
	""                       // Session ID (auto-generated if empty)
)
```

---

## ğŸ“œ License

MIT Â© [Mateusz Mierzwinski](LICENSE.md)